{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NCAA 2019\n",
    "===\n",
    "\n",
    "Two logistic regressions are ensembled to predict a March Madness bracket: the first is trained on team stats, and the second is trained on vegas moneylines/spreads.\n",
    "\n",
    "Underpinning\n",
    "---\n",
    "\n",
    "Before training the models, the necessary libraries and data are imported, helper methods are defined, and data is assembled into convenient data structures.\n",
    "\n",
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a helpers for importing CSV datasets and translating team names into a standardized team name across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_csv(path):\n",
    "    csv = pd.read_csv(path)\n",
    "    return np.asarray(csv)\n",
    "\n",
    "translator = {\n",
    "    \"Albany\": \"Albany NY\",\n",
    "    \"Massachusetts Lowell\": \"Massachusetts\",\n",
    "    \"MD Baltimore Cty\": \"Maryland\",\n",
    "    \"MD Baltimore County\": \"Maryland\",\n",
    "    \"NC-Wilmington\": \"UNC Wilmington\",\n",
    "    \"N.C. State\": \"NC State\",\n",
    "    \"N.C. St\": \"NC State\",\n",
    "    \"NC St\": \"NC State\",\n",
    "    \"N Carolina\": \"North Carolina\",\n",
    "    \"Southern Methodist\": \"SMU\",\n",
    "    \"Monmouth-NJ\": \"Monmouth NJ\",\n",
    "    \"Loyola-Maryland\": \"Loyola MD\",\n",
    "    \"UMKC\": \"Missouri KC\",\n",
    "    \"Kent St\": \"Kent\",\n",
    "    \"LIU Brooklyn\": \"Long Island\",\n",
    "    \"Wis.-Milwaukee\": \"WI Milwaukee\",\n",
    "    \"Boston U\": \"Boston Univ\",\n",
    "    \"Idaho State\": \"Idaho St\",\n",
    "    \"Stephen F. Austin\": \"SF Austin\",\n",
    "    \"Mount St Mary's\": \"Mt St Mary's\",\n",
    "    \"St Mary's\": \"St Mary's CA\",\n",
    "    \"Central Florida\": \"UCF\",\n",
    "    \"Saint Louis\": \"St Louis\",\n",
    "    \"Southern California\": \"USC\",\n",
    "    \"WVirginia\": \"West Virginia\",\n",
    "    \"Brigham Young\": \"BYU\",\n",
    "    \"Western Kentucky\": \"WKU\",\n",
    "    \"VCU\": \"VA Commonwealth\",\n",
    "    \"Southern Illinois\": \"S Illinois\",\n",
    "    \"St Joseph's\": \"St Joseph's PA\",\n",
    "    \"S Carolina\": \"South Carolina\",\n",
    "    \"Miami-Florida\": \"Miami FL\",\n",
    "    \"Miami (OH)\": \"Miami OH\",\n",
    "    \"N Iowa\": \"Northern Iowa\",\n",
    "    \"Western Michigan\": \"W Michigan\",\n",
    "    \"Louisiana St\": \"LSU\",\n",
    "    \"UC Santa Barbara\": \"Santa Barbara\",\n",
    "    \"Illinois-Chicago\": \"IL Chicago\",\n",
    "    \"S Florida\": \"South Florida\",\n",
    "    \"George Washington\": \"G Washington\",\n",
    "    \"Middle Tennessee St\": \"MTSU\",\n",
    "    \"Loyola Marymount\": \"Loy Marymount\",\n",
    "    \"Texas Christian\": \"TCU\",\n",
    "    \"Eastern Michigan\": \"E Michigan\",\n",
    "    \"NC-Greensboro\": \"UNC Greensboro\",\n",
    "    \"Texas-El Paso\": \"UTEP\",\n",
    "    \"Green Bay\": \"WI Green Bay\",\n",
    "    \"Eastern Washington\": \"E Washington\",\n",
    "    \"Central Michigan\": \"C Michigan\",\n",
    "    \"Cal St Fullerton\": \"CS Fullerton\",\n",
    "    \"S Alabama\": \"South Alabama\",\n",
    "    \"CSU Northridge\": \"CS Northridge\",\n",
    "    \"Western Carolina\": \"W Carolina\",\n",
    "    \"N Arizona\": \"Northern Arizona\",\n",
    "    \"Eastern Illinois\": \"E Illinois\",\n",
    "    \"Pennsylvania\": \"Penn\",\n",
    "    \"Georgia Southern\": \"Ga Southern\",\n",
    "    \"Eastern Kentucky\": \"E Kentucky\",\n",
    "    \"N Texas\": \"North Texas\",\n",
    "    \"Sacramento St\": \"CS Sacramento\",\n",
    "    \"Tenn-Martin\": \"TN Martin\",\n",
    "    \"E Carolina\": \"East Carolina\",\n",
    "    \"Florida International\": \"Florida Intl\",\n",
    "    \"Elon University\": \"Elon\",\n",
    "    \"Elon University\": \"Elon\",\n",
    "    \"Louisiana-Lafayette\": \"Lafayette\",\n",
    "    \"ULL\": \"Lafayette\",\n",
    "    \"Florida Atlantic\": \"FL Atlantic\",\n",
    "    \"Indiana - Purdue\": \"Purdue\",\n",
    "    \"E Tennessee St\": \"ETSU\",\n",
    "    \"Western Illinois\": \"W Illinois\",\n",
    "    \"Texas-Arlington\": \"UT Arlington\",\n",
    "    \"S Dakota\": \"South Dakota\",\n",
    "    \"N Dakota\": \"North Dakota\",\n",
    "    \"IUPU - Ft. Wayne\": \"Purdue Fort Wayne\",\n",
    "    \"SIU - Edwardsville\": \"Edwardsville\",\n",
    "    \"The Citadel\": \"Citadel\",\n",
    "    \"No.Carolina A&T\": \"NC A&T\",\n",
    "    \"Texas-San Antonio\": \"UT San Antonio\",\n",
    "    \"Nebraska Omaha\": \"NE Omaha\",\n",
    "    \"Coastal Carolina\": \"Coastal Car\",\n",
    "    \"Little Rock\": \"Ark Little Rock\",\n",
    "    \"Arkansas-Little Rock\": \"Ark Little Rock\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in historical teams and map the Kaggle ID to a standardized team name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_csv = from_csv('./data/teams.csv')\n",
    "\n",
    "team_ids = {}\n",
    "\n",
    "for index in range(0, len(teams_csv)):\n",
    "    team = teams_csv[index]\n",
    "    team_id = team[0]\n",
    "    team_name = team[1]\n",
    "    team_ids[team_id] = team_name\n",
    "\n",
    "# allows us to map a team id to its name: team_ids[1101] => Abilene Chr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a helpful intermediate data structure that allows us to quickly access stats for a given team in a given year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team name, adj offensive efficiency, adj defensive efficiency, adj tempo, luck, adj margin of efficiency, \n",
    "# strength of schedule margin, avg opponent offense, avg opponent defense, non-conference, conf, year\n",
    "kenpom_csv = from_csv(\"./data/kenpom.csv\")\n",
    "\n",
    "# transform conf to category\n",
    "conference_ids = {}\n",
    "unique_confs = np.unique(kenpom_csv[:, 10])\n",
    "for index in range(0, len(unique_confs)):\n",
    "    conference_ids[unique_confs[index]] = index\n",
    "\n",
    "# year > team > stats\n",
    "kenpom_team_stats_by_year = {}\n",
    "\n",
    "for index in range(0, len(kenpom_csv)):\n",
    "    team, offense, defense, tempo, luck, em, sos, oppoff, oppdef, nonconf, conf, year = kenpom_csv[index]\n",
    "    \n",
    "    if (not isinstance(kenpom_team_stats_by_year.get(year), dict)):\n",
    "        kenpom_team_stats_by_year[year] = {}\n",
    "    \n",
    "    kenpom_team_stats_by_year[year][team] = [offense, defense, tempo, luck, em, sos, oppoff, oppdef, nonconf, conference_ids[conf]]\n",
    "    \n",
    "# kenpom_team_stats_by_year[2002]['Kent']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the full game history since 2003 and create a helper for testing against historical matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Season, Day Num, Winning Team ID, Winning Score, Losing Team ID, Losing Score, Winner Location (Home/Away/Neu.),\n",
    "# Num OT, WFGM (Field Goals made), WFGA (attempted), WFGM3 (three pointers made), WFGA3, WFTM (free throws made),\n",
    "# WFTA (free throw attempted), WOR (offensive rebounds), WDR (defensive rebounds), WAst (assists), WTO (turnovers),\n",
    "# WStl (steals), WBlk (blocks), WPF (personal fouls), LFGM, LFGA, LFGM3, LFGA3, LFTM, LFTA, LOR, LDR, LAst, LTO, LStl, \n",
    "# LBlk, LPF\n",
    "raw_game_history = np.concatenate((\n",
    "    from_csv('./data/results.csv'),\n",
    "    from_csv('./data/prelim_2019_regular_season_detailed_results.csv'),\n",
    "))\n",
    "\n",
    "x_training_set = []\n",
    "y_training_set = []\n",
    "\n",
    "WIN = 1\n",
    "LOSS = 0\n",
    "\n",
    "for index in range(0, len(raw_game_history)):\n",
    "    row = raw_game_history[index]\n",
    "    year = row[0]\n",
    "    winning_team_id = row[2]\n",
    "    losing_team_id = row[4]\n",
    "    winning_team_name = team_ids[winning_team_id]\n",
    "    losing_team_name = team_ids[losing_team_id]\n",
    "    winning_team_location_letter = row[6]\n",
    "\n",
    "    if winning_team_location_letter == 'H':\n",
    "        wloc = 1\n",
    "        lloc = 0\n",
    "    if winning_team_location_letter == 'N':\n",
    "        wloc = 0.5\n",
    "        lloc = 0.5\n",
    "    if winning_team_location_letter == 'A':\n",
    "        wloc = 0\n",
    "        lloc = 1\n",
    "\n",
    "    if (not isinstance(kenpom_team_stats_by_year.get(year), dict)):\n",
    "        continue\n",
    "    if (not isinstance(kenpom_team_stats_by_year[year].get(winning_team_name), list)):\n",
    "        continue\n",
    "    if (not isinstance(kenpom_team_stats_by_year[year].get(losing_team_name), list)):\n",
    "        continue\n",
    "        \n",
    "    winner_stats = kenpom_team_stats_by_year[year][winning_team_name]\n",
    "    loser_stats = kenpom_team_stats_by_year[year][losing_team_name]\n",
    "        \n",
    "    x_training_set.append(np.concatenate((winner_stats, loser_stats, [wloc])))\n",
    "    y_training_set.append(WIN)\n",
    "    \n",
    "    # Append same outcome in both positions to avoid training the model on first position being winner\n",
    "    x_training_set.append(np.concatenate((loser_stats, winner_stats, [lloc])))\n",
    "    y_training_set.append(LOSS)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_training_set, y_training_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moneylines Model\n",
    "---\n",
    "\n",
    "A logistic regression is trained on historical Vegas spreads, and an accompanying linear regression is initialized to approximate match-ups for which the spread is unavilable (all games after the first round).\n",
    "\n",
    "Train a logistic regression on historical spreads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.73\n"
     ]
    }
   ],
   "source": [
    "raw_moneylines = from_csv('./data/spreads.csv')\n",
    "\n",
    "hyperparameters = {\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [100, 500, 1000, 5000, 10000, 50000, 100000],\n",
    "    'penalty': ['l2'],\n",
    "    'C': np.logspace(0, 4, 10),\n",
    "}\n",
    "\n",
    "spreads = raw_moneylines[:, 0].reshape(-1, 1)\n",
    "winloss = np.asarray(raw_moneylines[:, 1], dtype='int')\n",
    "\n",
    "moneylines_X_train, moneylines_X_test, moneylines_y_train, moneylines_y_test = train_test_split(spreads, winloss)\n",
    "\n",
    "spread_classifier = GridSearchCV(LogisticRegression(), hyperparameters, cv=5, verbose=0, error_score='raise')\n",
    "spread_classifier.fit(moneylines_X_train, moneylines_y_train)\n",
    "\n",
    "y_pred = spread_classifier.predict(moneylines_X_test)\n",
    "accuracy = np.mean(y_pred == moneylines_y_test)\n",
    "print(\"Test set score: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bracket must be submitted prior to the start of the tournament when Vegas spreads for only the first round are available, and after submitting the bracket, selections are immutable.  Any model based on Vegas spreads will then have to estimate future spreads.  To this end, a linear regression is initialized for the linear interpolation of unrealized spreads based on team stats.  Finally, the win/loss predictions based on the estimated pointspreads are compared against the win/loss predictions for the actual pointspreads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/base.py:485: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    }
   ],
   "source": [
    "team_stats = []\n",
    "stat_based_spreads = []\n",
    "\n",
    "errors = {}\n",
    "\n",
    "for index in range(0, len(raw_moneylines)):\n",
    "    moneyline, winloss, home_team_name, away_team_name, raw_year = raw_moneylines[index]\n",
    "    _, year = raw_year.split('-')\n",
    "    \n",
    "    home_team_name = translator.get(home_team_name, home_team_name)\n",
    "    away_team_name = translator.get(away_team_name, away_team_name)\n",
    "        \n",
    "    try:\n",
    "        home_stats = kenpom_team_stats_by_year[int(year)][home_team_name]\n",
    "        away_stats = kenpom_team_stats_by_year[int(year)][away_team_name]\n",
    "    \n",
    "        if home_stats and away_stats:\n",
    "            team_stats.append(np.concatenate((home_stats, away_stats)))\n",
    "            stat_based_spreads.append(moneyline)\n",
    "    except:\n",
    "        if errors.get(home_team_name):\n",
    "            errors[home_team_name] = errors[home_team_name] + 1\n",
    "        else:\n",
    "            errors[home_team_name] = 1\n",
    "            \n",
    "        if errors.get(away_team_name):\n",
    "            errors[away_team_name] = errors[away_team_name] + 1\n",
    "        else:\n",
    "            errors[away_team_name] = 1\n",
    "\n",
    "# print(sorted(errors.items(), key=lambda kv: -kv[1]))\n",
    "estimator_X_train, estimator_X_test, estimator_y_train, estimator_y_test = train_test_split(team_stats, stat_based_spreads)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(estimator_X_train, estimator_y_train)\n",
    "\n",
    "regressor.predict(estimator_X_test)\n",
    "\n",
    "estimated_moneylines_test_pred = regressor.predict(estimator_X_test).reshape(-1, 1)\n",
    "y_pred = spread_classifier.predict(estimated_moneylines_test_pred)\n",
    "actual = spread_classifier.predict(np.asarray(estimator_y_test).reshape(-1, 1))\n",
    "\n",
    "accuracy = np.mean(y_pred == actual)\n",
    "print(\"Test set score: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy of the model using estmates only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.74\n"
     ]
    }
   ],
   "source": [
    "estimated_moneylines_test_pred = regressor.predict(np.asarray(X_test)[:, :-1]).reshape(-1, 1)\n",
    "y_pred = spread_classifier.predict(estimated_moneylines_test_pred)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Test set score: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Stats Model\n",
    "---\n",
    "\n",
    "A logistic regression is trained on historical team stats and attempts to predict win/loss outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.78\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [1000, 5000],\n",
    "    'penalty': ['l2'],\n",
    "    'C': np.logspace(0, 4, 5),\n",
    "}\n",
    "\n",
    "kenpom_classifier = GridSearchCV(LogisticRegression(), hyperparameters, cv=5, verbose=0, error_score='raise')\n",
    "kenpom_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = kenpom_classifier.predict(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Test set score: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble\n",
    "---\n",
    "\n",
    "The two models are ensembled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.78\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "MONEYLINE_WEIGHT = 0.20\n",
    "KENPOM_WEIGHT = 0.80\n",
    "\n",
    "for index in range(0, len(X_test)):\n",
    "    row = np.asarray(X_test[index])\n",
    "    estimated_spread = regressor.predict([row[:-1]])\n",
    "    spread_based_pred = spread_classifier.predict_proba([estimated_spread])[0, 1]\n",
    "    kenpom_pred = kenpom_classifier.predict_proba([row])[0, 1]\n",
    "    win_probability = (MONEYLINE_WEIGHT * spread_based_pred) + (KENPOM_WEIGHT * kenpom_pred)\n",
    "    pred = 1 if win_probability >= 0.5 else 0\n",
    "    \n",
    "    predictions.append(pred)\n",
    "\n",
    "accuracy = np.mean(np.asarray(predictions) == y_test)\n",
    "print(\"Test set score: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output a CSV of all historical match predictions for upload to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncaa_matchups = from_csv('./data/matchups.csv')[:, 0]\n",
    "\n",
    "kaggle_predictions = [['ID', 'Pred']]\n",
    "\n",
    "NEUTRAL_LOCATION = 0.5\n",
    "\n",
    "for index in range(0, len(ncaa_matchups)):\n",
    "    match_id = ncaa_matchups[index]\n",
    "    _year, team_a_id, team_b_id = match_id.split(\"_\")\n",
    "    year = int(_year)\n",
    "    team_a_name = team_ids[int(team_a_id)]\n",
    "    team_b_name = team_ids[int(team_b_id)]\n",
    "    team_a_name = translator.get(team_a_name, team_a_name)\n",
    "    team_b_name = translator.get(team_b_name, team_b_name)\n",
    "    \n",
    "    team_a_stats = kenpom_team_stats_by_year[year][team_a_name]\n",
    "    team_b_stats = kenpom_team_stats_by_year[year][team_b_name]\n",
    "    \n",
    "    estimated_spread = regressor.predict([np.concatenate((team_a_stats, team_b_stats))])\n",
    "    spread_based_pred = spread_classifier.predict_proba([estimated_spread])[0, 1]\n",
    "    kenpom_pred = kenpom_classifier.predict_proba([np.concatenate((team_a_stats, team_b_stats, [NEUTRAL_LOCATION]))])[0, 1]\n",
    "    win_probability = (MONEYLINE_WEIGHT * spread_based_pred) + (KENPOM_WEIGHT * kenpom_pred)\n",
    "    \n",
    "    kaggle_predictions.append([match_id, win_probability])\n",
    "    \n",
    "pd.DataFrame(data=kaggle_predictions).to_csv('./data/kaggle_predictions_for_stage_1_with_ensemble_model.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output a CSV of potential 2018 bracket matchups for upload to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncaa_matchups = from_csv('./data/stage_2_sample_submission.csv')[:, 0]\n",
    "\n",
    "kaggle_predictions = [['ID', 'Pred']]\n",
    "\n",
    "NEUTRAL_LOCATION = 0.5\n",
    "\n",
    "for index in range(0, len(ncaa_matchups)):\n",
    "    match_id = ncaa_matchups[index]\n",
    "    _year, team_a_id, team_b_id = match_id.split(\"_\")\n",
    "    year = int(_year)\n",
    "    team_a_name = team_ids[int(team_a_id)]\n",
    "    team_b_name = team_ids[int(team_b_id)]\n",
    "    team_a_name = translator.get(team_a_name, team_a_name)\n",
    "    team_b_name = translator.get(team_b_name, team_b_name)\n",
    "    \n",
    "    team_a_stats = kenpom_team_stats_by_year[year][team_a_name]\n",
    "    team_b_stats = kenpom_team_stats_by_year[year][team_b_name]\n",
    "    \n",
    "    estimated_spread = regressor.predict([np.concatenate((team_a_stats, team_b_stats))])\n",
    "    spread_based_pred = spread_classifier.predict_proba([estimated_spread])[0, 1]\n",
    "    kenpom_pred = kenpom_classifier.predict_proba([np.concatenate((team_a_stats, team_b_stats, [NEUTRAL_LOCATION]))])[0, 1]\n",
    "    win_probability = (MONEYLINE_WEIGHT * spread_based_pred) + (KENPOM_WEIGHT * kenpom_pred)\n",
    "    \n",
    "    kaggle_predictions.append([match_id, win_probability])\n",
    "    \n",
    "pd.DataFrame(data=kaggle_predictions).to_csv('./data/kaggle_predictions_for_stage_2_with_ensemble_model.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a helper for filling out the office bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that Gonzaga beats Michigan is 0.57\n"
     ]
    }
   ],
   "source": [
    "NEUTRAL_LOCATION = 0.5\n",
    "def bracket_helper(team1, team2, actual_spread=None):\n",
    "    team1_stats = kenpom_team_stats_by_year[2019][team1]\n",
    "    team2_stats = kenpom_team_stats_by_year[2019][team2]\n",
    "    \n",
    "    if actual_spread != None:\n",
    "        spread = actual_spread\n",
    "    else:\n",
    "        spread = regressor.predict([np.concatenate((team1_stats, team2_stats))])\n",
    "        \n",
    "    spread_based_pred = spread_classifier.predict_proba([spread])[0, 1]\n",
    "    kenpom_pred = kenpom_classifier.predict_proba([np.concatenate((team1_stats, team2_stats, [NEUTRAL_LOCATION]))])[0, 1]\n",
    "    win_probability = (MONEYLINE_WEIGHT * spread_based_pred) + (KENPOM_WEIGHT * kenpom_pred)\n",
    "    \n",
    "    print(\"The probability that {} beats {} is {:.2f}\".format(team1, team2, win_probability))\n",
    "    \n",
    "bracket_helper(\"Gonzaga\", \"Michigan\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper to see what team names are available for 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Virginia', 'Gonzaga', 'Duke', 'Michigan St', 'Michigan', 'North Carolina', 'Kentucky', 'Tennessee', 'Texas Tech', 'Purdue', 'Virginia Tech', 'Wisconsin', 'Auburn', 'Florida St', 'Houston', 'Iowa St', 'LSU', 'Louisville', 'Wofford', 'Mississippi St', 'Kansas', 'Buffalo', 'Kansas St', 'Maryland', 'Nevada', 'Villanova', 'Florida', 'Marquette', 'Texas', \"St Mary's CA\", 'Clemson', 'Cincinnati', 'Utah St', 'NC State', 'Syracuse', 'Iowa', 'VA Commonwealth', 'Oklahoma', 'Nebraska', 'Penn St', 'Baylor', 'Mississippi', 'Oregon', 'Indiana', 'Ohio St', 'UCF', 'Minnesota', 'TCU', 'Lipscomb', 'Belmont', 'New Mexico St', 'Murray St', 'Washington', 'Creighton', 'Arkansas', 'Seton Hall', 'Furman', 'Toledo', 'Alabama', 'Dayton', 'Memphis', 'Arizona St', 'Liberty', 'Colorado', 'Xavier', 'San Francisco', 'ETSU', 'Missouri', 'Butler', 'South Carolina', 'Fresno St', 'Miami FL', 'Northwestern', 'UC Irvine', 'Rutgers', 'Providence', 'Temple', 'UNC Greensboro', 'Northeastern', 'Vermont', \"St John's\", 'Yale', 'Illinois', 'Oregon St', 'Davidson', 'BYU', 'Hofstra', 'USC', 'Texas A&M', 'Oklahoma St', 'Notre Dame', 'San Diego', 'Wichita St', 'S Dakota St', 'Georgetown', 'West Virginia', 'Pittsburgh', 'Arizona', 'Utah Valley', 'N Kentucky', 'Southern Miss', 'Ga Southern', 'Bowling Green', 'DePaul', 'St Louis', 'Grand Canyon', 'Akron', 'Connecticut', 'UCLA', 'Georgia Tech', 'Georgia St', 'Jacksonville St', 'Old Dominion', 'Utah', 'WKU', 'Boston College', 'SMU', 'Stanford', 'Col Charleston', 'St Bonaventure', 'South Florida', 'San Diego St', 'C Michigan', 'Wright St', 'Harvard', 'Radford', 'Texas St', 'Drake', 'Colgate', 'Georgia', 'Tulsa', 'Loyola-Chicago', 'Penn', 'Ball St', 'Austin Peay', 'N Illinois', 'Montana', 'Loy Marymount', 'Boise St', 'ULM', 'Louisiana Tech', 'Kent', 'Rhode Island', 'Samford', 'Abilene Chr', 'UAB', 'Bucknell', 'Brown', 'Miami OH', 'S Illinois', 'UT San Antonio', 'UT Arlington', 'Pepperdine', 'Vanderbilt', 'E Michigan', 'George Mason', 'North Texas', 'Charleston So', 'FL Atlantic', 'UNLV', 'Marshall', 'Coastal Car', 'NE Omaha', 'Bradley', 'Wake Forest', 'UTRGV', 'Santa Barbara', 'Stony Brook', 'Gardner Webb', 'North Florida', 'Lehigh', 'Missouri St', 'Duquesne', 'NJIT', 'Sam Houston St', 'Princeton', 'Northern Iowa', 'Louisiana', 'Colorado St', 'Winthrop', 'Seattle', 'Ohio', 'New Mexico', \"St Joseph's PA\", 'Santa Clara', 'Presbyterian', 'Oakland', 'Campbell', 'Purdue Fort Wayne', 'Hartford', 'IUPUI', 'N Colorado', 'Mercer', 'Cal Baptist', 'Hampton', 'Hawaii', 'American Univ', 'IL Chicago', 'Iona', 'N Dakota St', 'Florida Intl', 'Richmond', 'CS Fullerton', 'Illinois St', 'WI Green Bay', 'Appalachian St', 'F Dickinson', 'Indiana St', 'Washington St', 'South Alabama', 'FL Gulf Coast', 'Rider', 'Pacific', 'Columbia', 'TX Southern', 'Lamar', 'William & Mary', 'Prairie View', 'Dartmouth', 'Valparaiso', 'Ark Little Rock', 'Long Beach St', 'Cornell', 'Weber St', 'CS Bakersfield', 'La Salle', 'Evansville', 'High Point', 'South Dakota', 'UMBC', 'SE Louisiana', 'Boston Univ', 'Missouri KC', 'Quinnipiac', 'Massachusetts', 'Detroit', 'E Kentucky', 'Sacred Heart', 'E Washington', 'Holy Cross', 'Army', 'Air Force', 'MTSU', 'California', 'Drexel', 'Troy', 'UC Davis', 'Jacksonville', 'Rice', 'Morehead St', 'Citadel', 'W Michigan', 'Montana St', 'CS Northridge', 'Arkansas St', 'New Orleans', 'St Francis PA', 'Chattanooga', 'MA Lowell', 'Fordham', 'Long Island', 'Delaware', 'Youngstown St', 'Robert Morris', 'Norfolk St', 'Siena', 'North Dakota', 'Loyola MD', 'UNC Wilmington', 'East Carolina', 'W Carolina', 'St Francis NY', 'Grambling', 'Marist', 'CS Sacramento', 'Houston Bap', 'James Madison', 'Albany NY', 'Canisius', 'Navy', 'Southern Utah', 'TAM C. Christi', 'Cleveland St', 'VMI', 'North Alabama', 'Longwood', 'Portland St', 'Towson', 'TN Martin', 'Oral Roberts', 'G Washington', 'Tulane', 'W Illinois', 'Tennessee St', 'Monmouth NJ', 'Charlotte', 'Cent Arkansas', 'UTEP', 'WI Milwaukee', 'Lafayette', 'Fairfield', 'NC A&T', 'NC Central', 'Northern Arizona', 'Elon', 'E Illinois', 'Bethune-Cookman', 'SE Missouri St', 'Howard', 'Nicholls St', 'SF Austin', 'Denver', 'Wagner', 'Niagara', \"St Peter's\", 'Wyoming', 'Ark Pine Bluff', 'Florida A&M', 'Central Conn', 'UC Riverside', 'Jackson St', 'Tennessee Tech', \"Mt St Mary's\", 'Manhattan', 'Bryant', 'Stetson', 'Portland', 'Idaho St', 'Edwardsville', 'Alabama St', 'McNeese St', 'Binghamton', 'Cal Poly SLO', 'Morgan St', 'Southern Univ', 'SC Upstate', 'Maine', 'S Carolina St', 'Kennesaw', 'Savannah St', 'Northwestern LA', 'Coppin St', 'San Jose St', 'Alabama A&M', 'Incarnate Word', 'New Hampshire', 'Idaho', 'UNC Asheville', 'Alcorn St', 'MS Valley St', 'Chicago St', 'Delaware St', 'MD E Shore'])\n"
     ]
    }
   ],
   "source": [
    "print(kenpom_team_stats_by_year[2019].keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
