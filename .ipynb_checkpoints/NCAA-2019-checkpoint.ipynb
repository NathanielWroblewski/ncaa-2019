{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NCAA 2019\n",
    "===\n",
    "\n",
    "Two logistic regressions are ensembled to predict a March Madness bracket: the first is trained on team stats, and the second is trained on vegas moneylines/spreads.\n",
    "\n",
    "Underpinning\n",
    "---\n",
    "\n",
    "Before training the models, the necessary libraries and data are imported, helper methods are defined, and data is assembled into convenient data structures.\n",
    "\n",
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a helpers for importing CSV datasets and translating team names into a standardized team name across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_csv(path):\n",
    "    csv = pd.read_csv(path)\n",
    "    return np.asarray(csv)\n",
    "\n",
    "translator = {\n",
    "    \"Albany\": \"Albany NY\",\n",
    "    \"Massachusetts Lowell\": \"Massachusetts\",\n",
    "    \"MD Baltimore Cty\": \"Maryland\",\n",
    "    \"MD Baltimore County\": \"Maryland\",\n",
    "    \"NC-Wilmington\": \"UNC Wilmington\",\n",
    "    \"N.C. State\": \"NC State\",\n",
    "    \"N.C. St\": \"NC State\",\n",
    "    \"NC St\": \"NC State\",\n",
    "    \"N Carolina\": \"North Carolina\",\n",
    "    \"Southern Methodist\": \"SMU\",\n",
    "    \"Monmouth-NJ\": \"Monmouth NJ\",\n",
    "    \"Loyola-Maryland\": \"Loyola MD\",\n",
    "    \"UMKC\": \"Missouri KC\",\n",
    "    \"Kent St\": \"Kent\",\n",
    "    \"LIU Brooklyn\": \"Long Island\",\n",
    "    \"Wis.-Milwaukee\": \"WI Milwaukee\",\n",
    "    \"Boston U\": \"Boston Univ\",\n",
    "    \"Idaho State\": \"Idaho St\",\n",
    "    \"Stephen F. Austin\": \"SF Austin\",\n",
    "    \"Mount St Mary's\": \"Mt St Mary's\",\n",
    "    \"St Mary's\": \"St Mary's CA\",\n",
    "    \"Central Florida\": \"UCF\",\n",
    "    \"Saint Louis\": \"St Louis\",\n",
    "    \"Southern California\": \"USC\",\n",
    "    \"WVirginia\": \"West Virginia\",\n",
    "    \"Brigham Young\": \"BYU\",\n",
    "    \"Western Kentucky\": \"WKU\",\n",
    "    \"VCU\": \"VA Commonwealth\",\n",
    "    \"Southern Illinois\": \"S Illinois\",\n",
    "    \"St Joseph's\": \"St Joseph's PA\",\n",
    "    \"S Carolina\": \"South Carolina\",\n",
    "    \"Miami-Florida\": \"Miami FL\",\n",
    "    \"Miami (OH)\": \"Miami OH\",\n",
    "    \"N Iowa\": \"Northern Iowa\",\n",
    "    \"Western Michigan\": \"W Michigan\",\n",
    "    \"Louisiana St\": \"LSU\",\n",
    "    \"UC Santa Barbara\": \"Santa Barbara\",\n",
    "    \"Illinois-Chicago\": \"IL Chicago\",\n",
    "    \"S Florida\": \"South Florida\",\n",
    "    \"George Washington\": \"G Washington\",\n",
    "    \"Middle Tennessee St\": \"MTSU\",\n",
    "    \"Loyola Marymount\": \"Loy Marymount\",\n",
    "    \"Texas Christian\": \"TCU\",\n",
    "    \"Eastern Michigan\": \"E Michigan\",\n",
    "    \"NC-Greensboro\": \"UNC Greensboro\",\n",
    "    \"Texas-El Paso\": \"UTEP\",\n",
    "    \"Green Bay\": \"WI Green Bay\",\n",
    "    \"Eastern Washington\": \"E Washington\",\n",
    "    \"Central Michigan\": \"C Michigan\",\n",
    "    \"Cal St Fullerton\": \"CS Fullerton\",\n",
    "    \"S Alabama\": \"South Alabama\",\n",
    "    \"CSU Northridge\": \"CS Northridge\",\n",
    "    \"Western Carolina\": \"W Carolina\",\n",
    "    \"N Arizona\": \"Northern Arizona\",\n",
    "    \"Eastern Illinois\": \"E Illinois\",\n",
    "    \"Pennsylvania\": \"Penn\",\n",
    "    \"Georgia Southern\": \"Ga Southern\",\n",
    "    \"Eastern Kentucky\": \"E Kentucky\",\n",
    "    \"N Texas\": \"North Texas\",\n",
    "    \"Sacramento St\": \"CS Sacramento\",\n",
    "    \"Tenn-Martin\": \"TN Martin\",\n",
    "    \"E Carolina\": \"East Carolina\",\n",
    "    \"Florida International\": \"Florida Intl\",\n",
    "    \"Elon University\": \"Elon\",\n",
    "    \"Elon University\": \"Elon\",\n",
    "    \"Louisiana-Lafayette\": \"Lafayette\",\n",
    "    \"ULL\": \"Lafayette\",\n",
    "    \"Florida Atlantic\": \"FL Atlantic\",\n",
    "    \"Indiana - Purdue\": \"Purdue\",\n",
    "    \"E Tennessee St\": \"ETSU\",\n",
    "    \"Western Illinois\": \"W Illinois\",\n",
    "    \"Texas-Arlington\": \"UT Arlington\",\n",
    "    \"S Dakota\": \"South Dakota\",\n",
    "    \"N Dakota\": \"North Dakota\",\n",
    "    \"IUPU - Ft. Wayne\": \"Purdue Fort Wayne\",\n",
    "    \"SIU - Edwardsville\": \"Edwardsville\",\n",
    "    \"The Citadel\": \"Citadel\",\n",
    "    \"No.Carolina A&T\": \"NC A&T\",\n",
    "    \"Texas-San Antonio\": \"UT San Antonio\",\n",
    "    \"Nebraska Omaha\": \"NE Omaha\",\n",
    "    \"Coastal Carolina\": \"Coastal Car\",\n",
    "    \"Little Rock\": \"Ark Little Rock\",\n",
    "    \"Arkansas-Little Rock\": \"Ark Little Rock\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in historical teams and map the Kaggle ID to a standardized team name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_csv = from_csv('./data/teams.csv')\n",
    "\n",
    "team_ids = {}\n",
    "\n",
    "for index in range(0, len(teams_csv)):\n",
    "    team = teams_csv[index]\n",
    "    team_id = team[0]\n",
    "    team_name = team[1]\n",
    "    team_ids[team_id] = team_name\n",
    "\n",
    "# allows us to map a team id to its name: team_ids[1101] => Abilene Chr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a helpful intermediate data structure that allows us to quickly access stats for a given team in a given year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team name, adj offensive efficiency, adj defensive efficiency, adj tempo, luck, adj margin of efficiency, \n",
    "# strength of schedule margin, avg opponent offense, avg opponent defense, non-conference, conf, year\n",
    "kenpom_csv = from_csv(\"./data/kenpom.csv\")\n",
    "\n",
    "# transform conf to category\n",
    "conference_ids = {}\n",
    "unique_confs = np.unique(kenpom_csv[:, 10])\n",
    "for index in range(0, len(unique_confs)):\n",
    "    conference_ids[unique_confs[index]] = index\n",
    "\n",
    "# year > team > stats\n",
    "kenpom_team_stats_by_year = {}\n",
    "\n",
    "for index in range(0, len(kenpom_csv)):\n",
    "    team, offense, defense, tempo, luck, em, sos, oppoff, oppdef, nonconf, conf, year = kenpom_csv[index]\n",
    "    \n",
    "    if (not isinstance(kenpom_team_stats_by_year.get(year), dict)):\n",
    "        kenpom_team_stats_by_year[year] = {}\n",
    "    \n",
    "    kenpom_team_stats_by_year[year][team] = [offense, defense, tempo, luck, em, sos, oppoff, oppdef, nonconf, conference_ids[conf]]\n",
    "    \n",
    "# kenpom_team_stats_by_year[2002]['Kent']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the full game history since 2003 and create a helper for testing against historical matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Season, Day Num, Winning Team ID, Winning Score, Losing Team ID, Losing Score, Winner Location (Home/Away/Neu.),\n",
    "# Num OT, WFGM (Field Goals made), WFGA (attempted), WFGM3 (three pointers made), WFGA3, WFTM (free throws made),\n",
    "# WFTA (free throw attempted), WOR (offensive rebounds), WDR (defensive rebounds), WAst (assists), WTO (turnovers),\n",
    "# WStl (steals), WBlk (blocks), WPF (personal fouls), LFGM, LFGA, LFGM3, LFGA3, LFTM, LFTA, LOR, LDR, LAst, LTO, LStl, \n",
    "# LBlk, LPF\n",
    "raw_game_history = np.concatenate((\n",
    "    from_csv('./data/results.csv'),\n",
    "    from_csv('./data/prelim_2019_regular_season_detailed_results.csv'),\n",
    "))\n",
    "\n",
    "x_training_set = []\n",
    "y_training_set = []\n",
    "\n",
    "WIN = 1\n",
    "LOSS = 0\n",
    "\n",
    "for index in range(0, len(raw_game_history)):\n",
    "    row = raw_game_history[index]\n",
    "    year = row[0]\n",
    "    winning_team_id = row[2]\n",
    "    losing_team_id = row[4]\n",
    "    winning_team_name = team_ids[winning_team_id]\n",
    "    losing_team_name = team_ids[losing_team_id]\n",
    "    winning_team_location_letter = row[6]\n",
    "\n",
    "    if winning_team_location_letter == 'H':\n",
    "        wloc = 1\n",
    "        lloc = 0\n",
    "    if winning_team_location_letter == 'N':\n",
    "        wloc = 0.5\n",
    "        lloc = 0.5\n",
    "    if winning_team_location_letter == 'A':\n",
    "        wloc = 0\n",
    "        lloc = 1\n",
    "\n",
    "    if (not isinstance(kenpom_team_stats_by_year.get(year), dict)):\n",
    "        continue\n",
    "    if (not isinstance(kenpom_team_stats_by_year[year].get(winning_team_name), list)):\n",
    "        continue\n",
    "    if (not isinstance(kenpom_team_stats_by_year[year].get(losing_team_name), list)):\n",
    "        continue\n",
    "        \n",
    "    winner_stats = kenpom_team_stats_by_year[year][winning_team_name]\n",
    "    loser_stats = kenpom_team_stats_by_year[year][losing_team_name]\n",
    "        \n",
    "    x_training_set.append(np.concatenate((winner_stats, loser_stats, [wloc])))\n",
    "    y_training_set.append(WIN)\n",
    "    \n",
    "    # Append same outcome in both positions to avoid training the model on first position being winner\n",
    "    x_training_set.append(np.concatenate((loser_stats, winner_stats, [lloc])))\n",
    "    y_training_set.append(LOSS)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_training_set, y_training_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moneylines Model\n",
    "---\n",
    "\n",
    "A logistic regression is trained on historical Vegas spreads, and an accompanying linear regression is initialized to approximate match-ups for which the spread is unavilable (all games after the first round).\n",
    "\n",
    "Train a logistic regression on historical spreads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.74\n"
     ]
    }
   ],
   "source": [
    "raw_moneylines = from_csv('./data/spreads.csv')\n",
    "\n",
    "spreads = raw_moneylines[:, 0].reshape(-1, 1)\n",
    "winloss = np.asarray(raw_moneylines[:, 1], dtype='int')\n",
    "\n",
    "moneylines_X_train, moneylines_X_test, moneylines_y_train, moneylines_y_test = train_test_split(spreads, winloss)\n",
    "\n",
    "spread_classifier = LogisticRegression(solver = 'lbfgs', penalty='l2', max_iter=10000)\n",
    "spread_classifier.fit(moneylines_X_train, moneylines_y_train)\n",
    "\n",
    "y_pred = spread_classifier.predict(moneylines_X_test)\n",
    "accuracy = np.mean(y_pred == moneylines_y_test)\n",
    "print(\"Test set score: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bracket must be submitted prior to the start of the tournament when Vegas spreads for only the first round are available, and after submitting the bracket, selections are immutable.  Any model based on Vegas spreads will then have to estimate future spreads.  To this end, a linear regression is initialized for the linear interpolation of unrealized spreads based on team stats.  Finally, the win/loss predictions based on the estimated pointspreads are compared against the win/loss predictions for the actual pointspreads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/base.py:485: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    }
   ],
   "source": [
    "team_stats = []\n",
    "stat_based_spreads = []\n",
    "\n",
    "errors = {}\n",
    "\n",
    "for index in range(0, len(raw_moneylines)):\n",
    "    moneyline, winloss, home_team_name, away_team_name, raw_year = raw_moneylines[index]\n",
    "    _, year = raw_year.split('-')\n",
    "    \n",
    "    home_team_name = translator.get(home_team_name, home_team_name)\n",
    "    away_team_name = translator.get(away_team_name, away_team_name)\n",
    "        \n",
    "    try:\n",
    "        home_stats = kenpom_team_stats_by_year[int(year)][home_team_name]\n",
    "        away_stats = kenpom_team_stats_by_year[int(year)][away_team_name]\n",
    "    \n",
    "        if home_stats and away_stats:\n",
    "            team_stats.append(np.concatenate((home_stats, away_stats)))\n",
    "            stat_based_spreads.append(moneyline)\n",
    "    except:\n",
    "        if errors.get(home_team_name):\n",
    "            errors[home_team_name] = errors[home_team_name] + 1\n",
    "        else:\n",
    "            errors[home_team_name] = 1\n",
    "            \n",
    "        if errors.get(away_team_name):\n",
    "            errors[away_team_name] = errors[away_team_name] + 1\n",
    "        else:\n",
    "            errors[away_team_name] = 1\n",
    "\n",
    "# print(sorted(errors.items(), key=lambda kv: -kv[1]))\n",
    "estimator_X_train, estimator_X_test, estimator_y_train, estimator_y_test = train_test_split(team_stats, stat_based_spreads)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(estimator_X_train, estimator_y_train)\n",
    "\n",
    "regressor.predict(estimator_X_test)\n",
    "\n",
    "estimated_moneylines_test_pred = regressor.predict(estimator_X_test).reshape(-1, 1)\n",
    "y_pred = spread_classifier.predict(estimated_moneylines_test_pred)\n",
    "actual = spread_classifier.predict(np.asarray(estimator_y_test).reshape(-1, 1))\n",
    "\n",
    "accuracy = np.mean(y_pred == actual)\n",
    "print(\"Test set score: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy of the model using estmates only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.75\n"
     ]
    }
   ],
   "source": [
    "estimated_moneylines_test_pred = regressor.predict(np.asarray(X_test)[:, :-1]).reshape(-1, 1)\n",
    "y_pred = spread_classifier.predict(estimated_moneylines_test_pred)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Test set score: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Stats Model\n",
    "---\n",
    "\n",
    "A logistic regression is trained on historical team stats and attempts to predict win/loss outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.78\n"
     ]
    }
   ],
   "source": [
    "kenpom_classifier = LogisticRegression(solver = 'lbfgs', penalty='l2', max_iter=10000)\n",
    "kenpom_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = kenpom_classifier.predict(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Test set score: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble\n",
    "---\n",
    "\n",
    "The two models are ensembled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.78\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "MONEYLINE_WEIGHT = 0.20\n",
    "KENPOM_WEIGHT = 0.80\n",
    "\n",
    "for index in range(0, len(X_test)):\n",
    "    row = np.asarray(X_test[index])\n",
    "    estimated_spread = regressor.predict([row[:-1]])\n",
    "    spread_based_pred = spread_classifier.predict_proba([estimated_spread])[0, 1]\n",
    "    kenpom_pred = kenpom_classifier.predict_proba([row])[0, 1]\n",
    "    win_probability = (MONEYLINE_WEIGHT * spread_based_pred) + (KENPOM_WEIGHT * kenpom_pred)\n",
    "    pred = 1 if win_probability >= 0.5 else 0\n",
    "    \n",
    "    predictions.append(pred)\n",
    "\n",
    "accuracy = np.mean(np.asarray(predictions) == y_test)\n",
    "print(\"Test set score: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output a CSV of all historical match predictions for upload to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncaa_matchups = from_csv('./data/matchups.csv')[:, 0]\n",
    "\n",
    "kaggle_predictions = [['ID', 'Pred']]\n",
    "\n",
    "NEUTRAL_LOCATION = 0.5\n",
    "\n",
    "for index in range(0, len(ncaa_matchups)):\n",
    "    match_id = ncaa_matchups[index]\n",
    "    _year, team_a_id, team_b_id = match_id.split(\"_\")\n",
    "    year = int(_year)\n",
    "    team_a_name = team_ids[int(team_a_id)]\n",
    "    team_b_name = team_ids[int(team_b_id)]\n",
    "    team_a_name = translator.get(team_a_name, team_a_name)\n",
    "    team_b_name = translator.get(team_b_name, team_b_name)\n",
    "    \n",
    "    team_a_stats = kenpom_team_stats_by_year[year][team_a_name]\n",
    "    team_b_stats = kenpom_team_stats_by_year[year][team_b_name]\n",
    "    \n",
    "    estimated_spread = regressor.predict([np.concatenate((team_a_stats, team_b_stats))])\n",
    "    spread_based_pred = spread_classifier.predict_proba([estimated_spread])[0, 1]\n",
    "    kenpom_pred = kenpom_classifier.predict_proba([np.concatenate((team_a_stats, team_b_stats, [NEUTRAL_LOCATION]))])[0, 1]\n",
    "    win_probability = (MONEYLINE_WEIGHT * spread_based_pred) + (KENPOM_WEIGHT * kenpom_pred)\n",
    "    \n",
    "    kaggle_predictions.append([match_id, win_probability])\n",
    "    \n",
    "pd.DataFrame(data=kaggle_predictions).to_csv('./data/kaggle_predictions_for_stage_1_with_ensemble_model.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output a CSV of potential 2018 bracket matchups for upload to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncaa_matchups = from_csv('./data/stage_2_sample_submission.csv')[:, 0]\n",
    "\n",
    "kaggle_predictions = [['ID', 'Pred']]\n",
    "\n",
    "NEUTRAL_LOCATION = 0.5\n",
    "\n",
    "for index in range(0, len(ncaa_matchups)):\n",
    "    match_id = ncaa_matchups[index]\n",
    "    _year, team_a_id, team_b_id = match_id.split(\"_\")\n",
    "    year = int(_year)\n",
    "    team_a_name = team_ids[int(team_a_id)]\n",
    "    team_b_name = team_ids[int(team_b_id)]\n",
    "    team_a_name = translator.get(team_a_name, team_a_name)\n",
    "    team_b_name = translator.get(team_b_name, team_b_name)\n",
    "    \n",
    "    team_a_stats = kenpom_team_stats_by_year[year][team_a_name]\n",
    "    team_b_stats = kenpom_team_stats_by_year[year][team_b_name]\n",
    "    \n",
    "    estimated_spread = regressor.predict([np.concatenate((team_a_stats, team_b_stats))])\n",
    "    spread_based_pred = spread_classifier.predict_proba([estimated_spread])[0, 1]\n",
    "    kenpom_pred = kenpom_classifier.predict_proba([np.concatenate((team_a_stats, team_b_stats, [NEUTRAL_LOCATION]))])[0, 1]\n",
    "    win_probability = (MONEYLINE_WEIGHT * spread_based_pred) + (KENPOM_WEIGHT * kenpom_pred)\n",
    "    \n",
    "    kaggle_predictions.append([match_id, win_probability])\n",
    "    \n",
    "pd.DataFrame(data=kaggle_predictions).to_csv('./data/kaggle_predictions_for_stage_2_with_ensemble_model.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a helper for filling out the office bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that North Carolina beats Michigan St is 0.48\n"
     ]
    }
   ],
   "source": [
    "def bracket_helper(team1, team2, actual_spread=None):\n",
    "    team1_stats = kenpom_team_stats_by_year[2019][team1]\n",
    "    team2_stats = kenpom_team_stats_by_year[2019][team2]\n",
    "    \n",
    "    if actual_spread != None:\n",
    "        spread = actual_spread\n",
    "    else:\n",
    "        spread = regressor.predict([np.concatenate((team1_stats, team2_stats))])\n",
    "        \n",
    "    spread_based_pred = spread_classifier.predict_proba([spread])[0, 1]\n",
    "    kenpom_pred = kenpom_classifier.predict_proba([np.concatenate((team1_stats, team2_stats, [NEUTRAL_LOCATION]))])[0, 1]\n",
    "    win_probability = (MONEYLINE_WEIGHT * spread_based_pred) + (KENPOM_WEIGHT * kenpom_pred)\n",
    "    \n",
    "    print(\"The probability that {} beats {} is {:.2f}\".format(team1, team2, win_probability))\n",
    "    \n",
    "bracket_helper(\"North Carolina\", \"Michigan St\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper to see what team names are available for 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Virginia', 'Gonzaga', 'Duke', 'Michigan St', 'North Carolina', 'Michigan', 'Tennessee', 'Kentucky', 'Texas Tech', 'Purdue', 'Virginia Tech', 'Wisconsin', 'Houston', 'Auburn', 'Florida St', 'Kansas', 'LSU', 'Louisville', 'Iowa St', 'Mississippi St', 'Wofford', 'Buffalo', 'Kansas St', 'Maryland', 'Nevada', 'Villanova', 'Marquette', 'Florida', 'Texas', 'Clemson', \"St Mary's CA\", 'NC State', 'VA Commonwealth', 'Iowa', 'Syracuse', 'Cincinnati', 'UCF', 'Oklahoma', 'Utah St', 'Nebraska', 'Penn St', 'Indiana', 'Baylor', 'Mississippi', 'Ohio St', 'Minnesota', 'Washington', 'TCU', 'Oregon', 'Creighton', 'Murray St', 'Lipscomb', 'Belmont', 'Furman', 'Seton Hall', 'New Mexico St', 'Arkansas', 'Dayton', 'Toledo', 'Alabama', 'Arizona St', 'Liberty', 'Fresno St', 'Colorado', 'Xavier', 'San Francisco', 'Temple', 'Providence', 'ETSU', 'Davidson', 'Butler', 'South Carolina', 'Missouri', 'Miami FL', 'Northwestern', 'Memphis', 'Rutgers', 'Northeastern', \"St John's\", 'UNC Greensboro', 'UC Irvine', 'Illinois', 'Vermont', 'Yale', 'San Diego', 'Oregon St', 'BYU', 'USC', 'Notre Dame', 'Oklahoma St', 'Hofstra', 'Texas A&M', 'Utah Valley', 'Georgetown', 'West Virginia', 'Grand Canyon', 'Southern Miss', 'Connecticut', 'Pittsburgh', 'S Dakota St', 'Wichita St', 'Arizona', 'N Kentucky', 'Ga Southern', 'DePaul', 'Bowling Green', 'Akron', 'Georgia Tech', 'UCLA', 'Utah', 'Jacksonville St', 'Boston College', 'Old Dominion', 'SMU', 'South Florida', 'Stanford', 'Col Charleston', 'WKU', 'Penn', 'Texas St', 'Georgia St', 'C Michigan', 'Radford', 'Wright St', 'Harvard', 'Colgate', 'Drake', 'Tulsa', 'Loyola-Chicago', 'Georgia', 'Ball St', 'San Diego St', 'St Bonaventure', 'N Illinois', 'Austin Peay', 'St Louis', 'ULM', 'Loy Marymount', 'Boise St', 'Louisiana Tech', 'Rhode Island', 'Kent', 'Montana', 'Samford', 'Brown', 'Bucknell', 'UAB', 'Miami OH', 'Abilene Chr', 'UT San Antonio', 'S Illinois', 'Pepperdine', 'UT Arlington', 'George Mason', 'Vanderbilt', 'E Michigan', 'North Texas', 'Charleston So', 'FL Atlantic', 'Marshall', 'Coastal Car', 'Wake Forest', 'UNLV', 'Santa Barbara', 'Bradley', 'NE Omaha', 'Sam Houston St', 'UTRGV', 'Gardner Webb', 'Stony Brook', 'Lehigh', 'Duquesne', 'Missouri St', 'North Florida', 'Northern Iowa', 'Winthrop', 'Louisiana', 'Princeton', 'Colorado St', 'NJIT', 'Seattle', 'Ohio', \"St Joseph's PA\", 'New Mexico', 'Santa Clara', 'Campbell', 'Presbyterian', 'Oakland', 'Hartford', 'Purdue Fort Wayne', 'N Colorado', 'Cal Baptist', 'Hampton', 'IUPUI', 'Mercer', 'CS Fullerton', 'Hawaii', 'Iona', 'American Univ', 'IL Chicago', 'Richmond', 'Florida Intl', 'N Dakota St', 'Illinois St', 'WI Green Bay', 'Appalachian St', 'Weber St', 'Indiana St', 'F Dickinson', 'South Alabama', 'Washington St', 'Rider', 'Columbia', 'Pacific', 'TX Southern', 'William & Mary', 'Cornell', 'Dartmouth', 'Lamar', 'FL Gulf Coast', 'Prairie View', 'Ark Little Rock', 'Valparaiso', 'Long Beach St', 'CS Bakersfield', 'La Salle', 'Evansville', 'UMBC', 'High Point', 'South Dakota', 'Boston Univ', 'Quinnipiac', 'Massachusetts', 'SE Louisiana', 'Missouri KC', 'Detroit', 'E Kentucky', 'Sacred Heart', 'Holy Cross', 'Air Force', 'Army', 'California', 'MTSU', 'E Washington', 'Drexel', 'Rice', 'UC Davis', 'Troy', 'Jacksonville', 'Citadel', 'Arkansas St', 'New Orleans', 'W Michigan', 'Montana St', 'Morehead St', 'MA Lowell', 'Fordham', 'Chattanooga', 'CS Northridge', 'Delaware', 'St Francis PA', 'Norfolk St', 'Long Island', 'Youngstown St', 'Siena', 'Loyola MD', 'Robert Morris', 'North Dakota', 'UNC Wilmington', 'East Carolina', 'Grambling', 'W Carolina', 'Southern Utah', 'St Francis NY', 'Marist', 'CS Sacramento', 'Houston Bap', 'James Madison', 'Albany NY', 'Navy', 'Canisius', 'TAM C. Christi', 'Cleveland St', 'VMI', 'Longwood', 'North Alabama', 'Portland St', 'Towson', 'G Washington', 'TN Martin', 'Oral Roberts', 'Monmouth NJ', 'Tulane', 'W Illinois', 'Charlotte', 'Tennessee St', 'Lafayette', 'UTEP', 'Cent Arkansas', 'WI Milwaukee', 'NC A&T', 'Fairfield', 'Northern Arizona', 'Elon', 'Bethune-Cookman', 'E Illinois', 'Howard', 'NC Central', 'SE Missouri St', 'Nicholls St', 'SF Austin', 'Denver', 'Wagner', 'Niagara', \"St Peter's\", 'Wyoming', 'Ark Pine Bluff', 'Florida A&M', 'Central Conn', 'Jackson St', 'UC Riverside', 'Manhattan', \"Mt St Mary's\", 'Tennessee Tech', 'Bryant', 'Portland', 'Stetson', 'Alabama St', 'Idaho St', 'Edwardsville', 'McNeese St', 'Binghamton', 'Cal Poly SLO', 'Morgan St', 'Southern Univ', 'SC Upstate', 'Maine', 'S Carolina St', 'Kennesaw', 'Northwestern LA', 'Savannah St', 'Coppin St', 'San Jose St', 'Alabama A&M', 'Incarnate Word', 'New Hampshire', 'Idaho', 'UNC Asheville', 'Alcorn St', 'MS Valley St', 'Chicago St', 'Delaware St', 'MD E Shore'])\n"
     ]
    }
   ],
   "source": [
    "print(kenpom_team_stats_by_year[2019].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
